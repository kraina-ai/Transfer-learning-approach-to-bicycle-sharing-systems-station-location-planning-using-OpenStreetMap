{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0bc346ac4f0fa602f0832f03492fc478b53b4de00371d75702406557251e11c86",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc346ac4f0fa602f0832f03492fc478b53b4de00371d75702406557251e11c86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import ASCENDING, GEOSPHERE, MongoClient\n",
    "import pandas as pd\n",
    "from alive_progress import alive_bar\n",
    "from shapely.geometry import Point, mapping\n",
    "from keplergl import KeplerGl\n",
    "import shapely\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "from h3 import h3\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client.osmDataDB\n",
    "coll_cities = db.cities\n",
    "coll_hexes_filtered = db.hexesInCitiesFiltered\n",
    "coll_relations_filtered = db.relationsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8639  documents deleted\n"
     ]
    }
   ],
   "source": [
    "d = coll_relations_filtered.delete_many({ 'amenity': 'bicycle_rental' })\n",
    "print(d.deleted_count, \" documents deleted\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_CITY = 'Wroc≈Çaw'\n",
    "CURRENT_RESOLUTION = 9\n",
    "NEIGHBOURS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "city_id = coll_cities.find_one({'city': CURRENT_CITY})['city_id']\n",
    "city_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['aerialway',\n",
       " 'airports',\n",
       " 'buildings',\n",
       " 'culture_art_entertainment',\n",
       " 'education',\n",
       " 'emergency',\n",
       " 'finances',\n",
       " 'healthcare',\n",
       " 'historic',\n",
       " 'leisure',\n",
       " 'other',\n",
       " 'roads_bike',\n",
       " 'roads_drive',\n",
       " 'roads_walk',\n",
       " 'shops',\n",
       " 'sport',\n",
       " 'sustenance',\n",
       " 'tourism',\n",
       " 'transportation',\n",
       " 'water']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "categories = coll_relations_filtered.find({'city_id': city_id}, {'_id':0, 'category': 1}).distinct('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['aerialway',\n",
       " 'airports',\n",
       " 'buildings',\n",
       " 'culture_art_entertainment',\n",
       " 'education',\n",
       " 'emergency',\n",
       " 'finances',\n",
       " 'healthcare',\n",
       " 'historic',\n",
       " 'leisure',\n",
       " 'other',\n",
       " 'roads_bike',\n",
       " 'roads_drive',\n",
       " 'roads_walk',\n",
       " 'shops',\n",
       " 'sport',\n",
       " 'sustenance',\n",
       " 'tourism',\n",
       " 'transportation',\n",
       " 'water']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(categories)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedHexBaseline(hex):\n",
    "    # hex = coll_hexes_filtered.find_one({'hex_id': hex_id})\n",
    "    relations = coll_relations_filtered.find({\n",
    "        \"geometry\": {\n",
    "            \"$geoIntersects\": {\n",
    "                \"$geometry\": hex['geometry']\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    functions = ' '.join([r['category'] for r in relations])\n",
    "    vector = vectorizer.transform([functions])\n",
    "    # print(functions)\n",
    "    # print(vector)\n",
    "    return vector.toarray().reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_bike roads_bike shops roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk roads_walk\n  (0, 14)\t0.025598984252456894\n  (0, 13)\t0.9983603858458189\n  (0, 11)\t0.05119796850491379\n"
     ]
    }
   ],
   "source": [
    "embedHexBaseline('897ab094db3ffff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations = [hex for hex in coll_hexes_filtered.find({ 'city_id': city_id, 'has_station': True, 'resolution': CURRENT_RESOLUTION })]\n",
    "stations_length = len(all_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "stations_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_vectors = [embedHexBaseline(h) for h in all_stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "INBALANCE_RATIO = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stations_cursor = coll_hexes_filtered.aggregate([\n",
    "    { '$match': { 'city_id': city_id, 'has_station': False, 'resolution': CURRENT_RESOLUTION } },\n",
    "    { '$sample': { 'size': stations_length * INBALANCE_RATIO } }\n",
    "])\n",
    "non_stations = [hex for hex in non_stations_cursor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1065"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "len(non_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_station_vectors = [embedHexBaseline(h) for h in non_stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(station_vectors + non_station_vectors)\n",
    "Y = np.array([1] * stations_length + [0] * len(non_stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1278, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1278,)"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.90      0.92      0.91       213\n           1       0.56      0.47      0.51        43\n\n    accuracy                           0.85       256\n   macro avg       0.73      0.69      0.71       256\nweighted avg       0.84      0.85      0.84       256\n\n              precision    recall  f1-score   support\n\n           0       0.91      0.93      0.92       213\n           1       0.62      0.53      0.57        43\n\n    accuracy                           0.87       256\n   macro avg       0.77      0.73      0.75       256\nweighted avg       0.86      0.87      0.86       256\n\n              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90       213\n           1       0.51      0.49      0.50        43\n\n    accuracy                           0.84       256\n   macro avg       0.70      0.70      0.70       256\nweighted avg       0.83      0.84      0.83       256\n\n"
     ]
    }
   ],
   "source": [
    "for _cls in [KNeighborsClassifier, RandomForestClassifier, DecisionTreeClassifier]:\n",
    "    clf = _cls()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # scores = cross_val_score(clf, X, Y, cv=5, scoring='f1_macro')\n",
    "    # print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}