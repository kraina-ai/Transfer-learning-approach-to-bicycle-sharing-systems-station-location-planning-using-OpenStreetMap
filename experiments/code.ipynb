{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0bc346ac4f0fa602f0832f03492fc478b53b4de00371d75702406557251e11c86",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc346ac4f0fa602f0832f03492fc478b53b4de00371d75702406557251e11c86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import ASCENDING, GEOSPHERE, MongoClient\n",
    "import pandas as pd\n",
    "from alive_progress import alive_bar\n",
    "from shapely.geometry import Point, mapping\n",
    "from keplergl import KeplerGl\n",
    "import shapely\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "from h3 import h3\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neighbour_embedding_methods import AverageDiminishingNeighbourEmbedding, AverageDiminishingSquqredNeighbourEmbedding, AverageNeighbourEmbedding, ConcatenateNeighbourEmbedding\n",
    "from custom_distance_metric import DistanceMetric\n",
    "from embedding_methods import BaseTfIdfCategoryEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INBALANCE_RATIOS = [1, 2, 3, 5]\n",
    "RESOLUTIONS = [9, 10, 11]\n",
    "NEIGHBORS = {\n",
    "    9: [0,1,2,3],\n",
    "    10: [0,2,4,6,8,10],\n",
    "    11: [0,5,10,15,20,25]\n",
    "}\n",
    "CLASSIFIERS = [KNeighborsClassifier, SVC, RandomForestClassifier, AdaBoostClassifier]\n",
    "NEIGHBORS_EMBEDDING_CLASSES = [ConcatenateNeighbourEmbedding, AverageNeighbourEmbedding, AverageDiminishingNeighbourEmbedding, AverageDiminishingSquqredNeighbourEmbedding]\n",
    "EMBEDDING_CLASSES = [BaseTfIdfCategoryEmbedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client.osmDataDB\n",
    "coll_cities = db.cities\n",
    "coll_hexes_filtered = db.hexesInCitiesFiltered\n",
    "coll_relations_filtered = db.relationsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'city_id': 1, 'city': 'Antwerpen'},\n",
       " {'city_id': 2, 'city': 'Barcelona'},\n",
       " {'city_id': 3, 'city': 'Berlin'},\n",
       " {'city_id': 4, 'city': 'Bern'},\n",
       " {'city_id': 5, 'city': 'Bordeaux'},\n",
       " {'city_id': 7, 'city': 'Brno'},\n",
       " {'city_id': 8, 'city': 'Bruxelles'},\n",
       " {'city_id': 10, 'city': 'Budapest'},\n",
       " {'city_id': 11, 'city': 'Cardiff'},\n",
       " {'city_id': 17, 'city': 'Dublin'},\n",
       " {'city_id': 24, 'city': 'Gothenburg'},\n",
       " {'city_id': 25, 'city': 'Helsinki'},\n",
       " {'city_id': 26, 'city': 'Kyiv'},\n",
       " {'city_id': 30, 'city': 'London'},\n",
       " {'city_id': 32, 'city': 'Lyon'},\n",
       " {'city_id': 33, 'city': 'Madrid'},\n",
       " {'city_id': 35, 'city': 'Marseille'},\n",
       " {'city_id': 36, 'city': 'Milan'},\n",
       " {'city_id': 37, 'city': 'Moscow'},\n",
       " {'city_id': 38, 'city': 'Munich'},\n",
       " {'city_id': 39, 'city': 'Nantes'},\n",
       " {'city_id': 41, 'city': 'Oslo'},\n",
       " {'city_id': 42, 'city': 'Ostrava'},\n",
       " {'city_id': 45, 'city': 'Paris'},\n",
       " {'city_id': 46, 'city': 'Poznań'},\n",
       " {'city_id': 47, 'city': 'Prague'},\n",
       " {'city_id': 49, 'city': 'Seville'},\n",
       " {'city_id': 52, 'city': 'Toulouse'},\n",
       " {'city_id': 55, 'city': 'Valencia'},\n",
       " {'city_id': 56, 'city': 'Vienna'},\n",
       " {'city_id': 58, 'city': 'Warszawa'},\n",
       " {'city_id': 59, 'city': 'Wrocław'},\n",
       " {'city_id': 60, 'city': 'Zaragoza'},\n",
       " {'city_id': 61, 'city': 'Zurich'}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "cities = [c for c in coll_cities.find({'accepted': True}, {'_id': 0, 'city_id': 1, 'city': 1})]\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7480\n"
     ]
    }
   ],
   "source": [
    "combinations = []\n",
    "for city in cities:\n",
    "    for resolution in RESOLUTIONS:\n",
    "        for inbalance_ratio in INBALANCE_RATIOS:\n",
    "            for embedding_cls in EMBEDDING_CLASSES:\n",
    "                for neighbours in NEIGHBORS[resolution]:\n",
    "                    if neighbours == 0:\n",
    "                        combinations.append({\n",
    "                            'city': city,\n",
    "                            'resolution': resolution,\n",
    "                            'inbalance_ratio': inbalance_ratio,\n",
    "                            'embedding_cls': embedding_cls,\n",
    "                            'neighbours': neighbours,\n",
    "                            'neighbour_embedding_cls': ConcatenateNeighbourEmbedding\n",
    "                        })\n",
    "                    else:\n",
    "                        for neighbour_embedding_cls in NEIGHBORS_EMBEDDING_CLASSES:\n",
    "                            combinations.append({\n",
    "                                'city': city,\n",
    "                                'resolution': resolution,\n",
    "                                'inbalance_ratio': inbalance_ratio,\n",
    "                                'embedding_cls': embedding_cls,\n",
    "                                'neighbours': neighbours,\n",
    "                                'neighbour_embedding_cls': neighbour_embedding_cls\n",
    "                            })\n",
    "print(len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xy(city_id, resolution, inbalance_ratio, neighbours, neighbour_embedding_cls, embedding_cls):\n",
    "    relation_embedder = embedding_cls()\n",
    "    relation_embedder.fit({ 'city_id': city_id })\n",
    "    all_stations = [hex for hex in coll_hexes_filtered.find({ 'city_id': city_id, 'has_station': True, 'resolution': resolution })]\n",
    "    stations_length = len(all_stations)\n",
    "    non_stations_cursor = coll_hexes_filtered.aggregate([\n",
    "        { '$match': { 'city_id': city_id, 'has_station': False, 'resolution': resolution } },\n",
    "        { '$sample': { 'size': stations_length * inbalance_ratio } }\n",
    "    ])\n",
    "    non_stations = [hex for hex in non_stations_cursor]\n",
    "    hex_id_list =  [h['hex_id'] for h in all_stations + non_stations]\n",
    "    y = np.array([1] * stations_length + [0] * len(non_stations))\n",
    "    embedder = neighbour_embedding_cls()\n",
    "    vectors_list = [embedder.get_embedding(h, neighbours, relation_embedder) for h in all_stations + non_stations]\n",
    "    # vectors = np.stack(vectors_list, axis=0)\n",
    "    vectors = np.array(vectors_list)\n",
    "    # vectors[np.isfinite(vectors) == True] = 0\n",
    "    try:\n",
    "        vectors[np.isnan(vectors) == True] = 0\n",
    "    except:\n",
    "        print(vectors)\n",
    "    return vectors, y, hex_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_combination(t):\n",
    "    params, idx = t\n",
    "    # print(params)\n",
    "    results = []\n",
    "    city = params['city']\n",
    "    resolution = params['resolution']\n",
    "    inbalance_ratio = params['inbalance_ratio']\n",
    "    embedding_cls = params['embedding_cls']\n",
    "    neighbours = params['neighbours']\n",
    "    neighbour_embedding_cls = params['neighbour_embedding_cls'] \n",
    "    custom_metric = DistanceMetric()\n",
    "    best_clf_dict = {}\n",
    "\n",
    "    desc = f'[{idx}] {city[\"city\"]} Res: {resolution} InbR: {inbalance_ratio} EmbCls: {embedding_cls.__name__} NeighEmbCls: {neighbour_embedding_cls.__name__} Neigh: {neighbours}'\n",
    "\n",
    "    with tqdm(total=10 * 10 * len(CLASSIFIERS), desc=desc, lock_args=(False,)) as pbar:\n",
    "        for iteration in range(10):\n",
    "            x, y, hex_ids = generate_xy(city['city_id'], resolution, inbalance_ratio, neighbours, neighbour_embedding_cls, embedding_cls)\n",
    "\n",
    "            y_hex_zip = list(zip(y, hex_ids))\n",
    "\n",
    "            X_tmp, X_validation, Y_hex_id_tmp, Y_hex_id_validation = train_test_split(x, y_hex_zip, test_size=0.2, stratify=y)\n",
    "\n",
    "            X_validation = np.array(X_validation)\n",
    "            Y_validation, hex_ids_validation = zip(*Y_hex_id_validation)\n",
    "            Y_validation = np.array(list(Y_validation))\n",
    "            hex_ids_validation = list(hex_ids_validation)\n",
    "\n",
    "            y_tmp = [t[0] for t in Y_hex_id_tmp]\n",
    "\n",
    "            clf_values = {}\n",
    "\n",
    "            for _ in range(10):\n",
    "                X_train, X_test, Y_hex_id_train, Y_hex_id_test = train_test_split(X_tmp, Y_hex_id_tmp, test_size=0.25, stratify=y_tmp)\n",
    "                X_train = np.array(X_train)\n",
    "                Y_train, hex_ids_train = zip(*Y_hex_id_train)\n",
    "                Y_train = np.array(list(Y_train))\n",
    "                hex_ids_train = list(hex_ids_train)\n",
    "                X_test = np.array(X_test)\n",
    "                Y_test, hex_ids_test = zip(*Y_hex_id_test)\n",
    "                Y_test = np.array(list(Y_test))\n",
    "                hex_ids_test = list(hex_ids_test)\n",
    "\n",
    "                for clf_cls in CLASSIFIERS:\n",
    "                    clf = clf_cls()\n",
    "                    try:\n",
    "                        clf.fit(X_train, Y_train)\n",
    "                    except:\n",
    "                        print(X_train)\n",
    "                        print(X_train.shape)\n",
    "                        print(np.any(np.isnan(X_train)))\n",
    "                        print(np.all(np.isfinite(X_train)))\n",
    "                        raise\n",
    "\n",
    "                    try:\n",
    "                        y_pred = clf.predict(X_test)\n",
    "                    except:\n",
    "                        print(X_test)\n",
    "                        print(X_test.shape)\n",
    "                        print(np.any(np.isnan(X_test)))\n",
    "                        print(np.all(np.isfinite(X_test)))\n",
    "                        raise\n",
    "\n",
    "                    acc = accuracy_score(y_pred=y_pred, y_true=Y_test)\n",
    "                    f1 = f1_score(y_pred=y_pred, y_true=Y_test)\n",
    "                    # custom_metric_value = custom_metric.calculate(Y_test, y_pred, hex_ids_test)\n",
    "                    if not clf_cls.__name__ in clf_values:\n",
    "                        clf_values[clf_cls.__name__] = {\n",
    "                            'accuracy': [],\n",
    "                            'f1': []\n",
    "                        }\n",
    "                    clf_values[clf_cls.__name__]['accuracy'].append(acc)\n",
    "                    clf_values[clf_cls.__name__]['f1'].append(f1)\n",
    "                    if not clf_cls.__name__ in best_clf_dict or f1 > best_clf_dict[clf_cls.__name__][0]:\n",
    "                        best_clf_dict[clf_cls.__name__] = (f1, clf)\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "            for k, v in clf_values.items():\n",
    "                results.append({\n",
    "                    'city': city['city'],\n",
    "                    'resolution': resolution,\n",
    "                    'inbalance_ratio': inbalance_ratio,\n",
    "                    'embedding_cls': embedding_cls.__name__,\n",
    "                    'neighbours': neighbours,\n",
    "                    'neighbour_embedding_cls': neighbour_embedding_cls.__name__,\n",
    "                    'classfier_cls': k,\n",
    "                    'iteration': iteration + 1,\n",
    "                    'dataset_type': 'test',\n",
    "                    'accuracy': np.average(v['accuracy']),\n",
    "                    'f1_score': np.average(v['f1']),\n",
    "                    # 'custom_metric': custom_metric_value\n",
    "                })\n",
    "            \n",
    "            for k, v in best_clf_dict.items():\n",
    "                y_pred = v[1].predict(X_validation)\n",
    "                acc = accuracy_score(y_pred=y_pred, y_true=Y_validation)\n",
    "                f1 = f1_score(y_pred=y_pred, y_true=Y_validation)\n",
    "                # custom_metric_value = custom_metric.calculate(Y_validation, y_pred, hex_ids_validation)\n",
    "                results.append({\n",
    "                    'city': city['city'],\n",
    "                    'resolution': resolution,\n",
    "                    'inbalance_ratio': inbalance_ratio,\n",
    "                    'embedding_cls': embedding_cls.__name__,\n",
    "                    'neighbours': neighbours,\n",
    "                    'neighbour_embedding_cls': neighbour_embedding_cls.__name__,\n",
    "                    'classfier_cls': k,\n",
    "                    'iteration': iteration + 1,\n",
    "                    'dataset_type': 'validation',\n",
    "                    'accuracy': acc,\n",
    "                    'f1_score': f1,\n",
    "                    # 'custom_metric': custom_metric_value\n",
    "                })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'results/result_{city[\"city\"]}_{time.strftime(\"%Y%m%d-%H%M%S\")}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[77] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 2:  70%|██████▉   | 279/400 [01:04<00:10, 11.91it/s]None neighbours!\n",
      "[77] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 2: 100%|██████████| 400/400 [01:27<00:00,  4.60it/s]\n",
      "[78] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 4:  90%|████████▉ | 359/400 [02:47<00:03, 11.51it/s]None neighbours!\n",
      "[78] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 4: 100%|██████████| 400/400 [03:01<00:00,  2.20it/s]\n",
      "[79] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageNeighbourEmbedding Neigh: 4: 100%|██████████| 400/400 [02:01<00:00,  3.30it/s]\n",
      "[80] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 4:  10%|▉         | 39/400 [00:09<00:39,  9.20it/s]None neighbours!\n",
      "[80] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 4:  70%|██████▉   | 278/400 [01:05<00:08, 14.88it/s]None neighbours!\n",
      "[80] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 4: 100%|██████████| 400/400 [01:30<00:00,  4.40it/s]\n",
      "[81] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 4: 100%|██████████| 400/400 [01:15<00:00,  5.30it/s]\n",
      "[82] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 6:  90%|████████▉ | 359/400 [03:32<00:04,  9.26it/s]None neighbours!\n",
      "[82] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 6: 100%|██████████| 400/400 [03:51<00:00,  1.73it/s]\n",
      "[83] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageNeighbourEmbedding Neigh: 6: 100%|██████████| 400/400 [02:27<00:00,  2.71it/s]\n",
      "[84] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 6: 100%|██████████| 400/400 [01:53<00:00,  3.52it/s]\n",
      "[85] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 6:   0%|          | 0/400 [00:00<?, ?it/s]None neighbours!\n",
      "[85] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 6: 100%|██████████| 400/400 [01:31<00:00,  4.39it/s]\n",
      "[86] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 8: 100%|██████████| 400/400 [04:57<00:00,  1.34it/s]\n",
      "[87] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageNeighbourEmbedding Neigh: 8: 100%|██████████| 400/400 [03:01<00:00,  2.20it/s]\n",
      "[88] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 8:  44%|████▍     | 175/400 [01:09<01:29,  2.50it/s][[0.         0.00063382 0.         ... 0.         0.00970467 0.        ]\n",
      " [0.         0.         0.         ... 0.00521653 0.         0.03027119]\n",
      " [0.         0.         0.         ... 0.         0.00055671 0.        ]\n",
      " ...\n",
      " [0.         0.00156528 0.         ... 0.00878719 0.00292014 0.00033189]\n",
      " [0.         0.00086789 0.         ... 0.00120159 0.01593315 0.01127343]\n",
      " [0.         0.         0.0101369  ... 0.00384587 0.0143174  0.        ]]\n",
      "(518, 19)\n",
      "False\n",
      "True\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-41071013d88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0miterate_combination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-145-4a2e0c5a2450>\u001b[0m in \u001b[0;36miterate_combination\u001b[0;34m(params, idx)\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \"\"\"\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# skip = 77\n",
    "# for idx, combination in enumerate(combinations):\n",
    "#     if idx < skip:\n",
    "#         continue\n",
    "#     iterate_combination(combination, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "pairs = []\n",
    "skip = 88\n",
    "for idx, combination in enumerate(combinations):\n",
    "    if idx < skip:\n",
    "        continue\n",
    "    pairs.append((combination, idx))\n",
    "\n",
    "# process_map(iterate_combination, pairs, max_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "[93] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 10:   0%|          | 0/400 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "[97] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 2:   0%|          | 0/400 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[92] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 10:   0%|          | 0/400 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[89] Antwerpen Res: 10 InbR: 2 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 8:   0%|          | 0/400 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[94] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 0:   0%|          | 1/400 [00:07<48:59,  7.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[94] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 0:   0%|          | 2/400 [00:07<34:25,  5.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-984c5b811b39>\", line 20, in <module>\n",
      "    p.map(partial(iterate_combination), pairs)\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/concurrent/futures/_base.py\", line 636, in __exit__\n",
      "    self.shutdown(wait=True)\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/concurrent/futures/thread.py\", line 236, in shutdown\n",
      "    t.join()\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/raczeq/anaconda3/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[94] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 0:   1%|          | 3/400 [00:13<36:47,  5.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[94] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 0:   1%|          | 4/400 [00:16<30:50,  4.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[94] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 0:   1%|▏         | 5/400 [00:16<22:16,  3.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[94] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 0:   2%|▏         | 6/400 [00:17<15:46,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[98] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingSquqredNeighbourEmbedding Neigh: 2:   0%|          | 1/400 [00:18<2:00:01, 18.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "[97] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageDiminishingNeighbourEmbedding Neigh: 2:   0%|          | 1/400 [00:18<2:01:44, 18.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "[96] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: AverageNeighbourEmbedding Neigh: 2:   0%|          | 1/400 [00:18<2:03:33, 18.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[95] Antwerpen Res: 10 InbR: 3 EmbCls: BaseTfIdfCategoryEmbedding NeighEmbCls: ConcatenateNeighbourEmbedding Neigh: 2:   0%|          | 1/400 [00:19<2:07:30, 19.17s/it]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, RLock, freeze_support\n",
    "from random import random\n",
    "from threading import RLock as TRLock\n",
    "from time import sleep\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "\n",
    "PY2 = sys.version_info[:1] <= (2,)\n",
    "tqdm.set_lock(TRLock())\n",
    "pool_args = {}\n",
    "if not PY2:\n",
    "    pool_args.update(initializer=tqdm.set_lock, initargs=(tqdm.get_lock(),))\n",
    "with ThreadPoolExecutor(**pool_args) as p:\n",
    "    p.map(partial(iterate_combination), pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}